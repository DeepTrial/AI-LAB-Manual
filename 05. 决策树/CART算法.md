# CART算法

CART算法（classification and regression tree）是在给定输入随机变量X条件下输出随机变量Y的条件概率分布的学习方法。CART算法可用于分类和回归。CART假设决策树是**二叉树**，内部结点特征的取值为”是“或”否“，左分支取值为“是”，右分支取值为”否“。

CART算法由以下2个步骤组成：

- 决策树生成：基于训练数据生成决策树，生成的决策树要尽量大
- 决策树剪枝：用验证集对生成的决策树进行剪枝并选择最优子树。



## 1.CART生成

对于回归问题，CART使用平方误差最小化准则；对于分类问题，使用基尼指数最小化准则，进行特征选择，生成二叉树。

### 1.1 回归树生成

回归树对应着输入空间的一个划分以及在划分的单元上的输出值。假设输入空间划分为M个单元$R_1,R_2,...,R_M$，并且在每个单元$R_m$上有一个固定的输出$c_m$，回归树模型可表示为：
$$
f(x)=\sum_{m=1}^Mc_mI(x \in R_m)
$$
回归树的生成算法如下：

在训练集所在的输入空间中，递归地将每个区域划分为两个子区域并决定每个子区域上的输出值，构建二叉决策树：

- 选择最优切分变量$j$与切分点$s$，求解
  $$
  \mathop{\min}_{j,s}\left[\mathop{min}_{c_1}\sum_{x_i \in R_1(j,s)}(y_i-c_1)^2+\mathop{min}_{c_1}\sum_{x_i \in R_1(j,s)}(y_i-c_2)^2\right]
  $$
  
  遍历变量$j$，对固定的切分变量$j$，扫描切分点$s$，选择使上式达到最小值的对$(j,s)$
  
- 使用选的$(j,s)$划分区域并决定相应的输出值：
  $$
  R_1(j,s)=\{x|x^{(j)}<=s\} \quad R_2(j,s)=\{x|x^{(j)}>s\}\\
  \hat{c_m}=\frac{1}{N_m}\sum_{x_i \in R_1(j,s)}y_i, \quad x \in R_m, \quad m=1,2
  $$

- 继续对两个子区域调用上述2个步骤，直至满足停止条件

- 将输入空间划分为M个区域，生成决策树：
  $$
  f(x)=\sum_{m=1}^Mc_mI(x \in R_m)
  $$

### 1.2分类树生成

分类树使用基尼指数选择最优特征，同时决定该特征的最优二值切分点

具体流程如下：

输入：训练数据集D，停止计算的条件

输出：CART决策树

递归过程：

- 计算所有特征的基尼指数。针对现有数据集，计算现有特征对该数据集的基尼指数。对于每一个特征A，对其可能取得每个值$\alpha$，根据样本点对于$A=\alpha$，测试是或否，将数据集D分割为$D_1$和$D_2$两个部分，计算$A=\alpha$得条件基尼指数
- 查找最优特征及其最优切分点。对所有可能得特征A以及其所有可能得切分点$\alpha$，选择基尼指数最小的特征作为最有特征与最优切分点。从现结点生成2个子结点，将训练集特征分配到两个子结点中去。
- 对两个子结点递归调用上面2个步骤，直到满足停止条件
- 生成CART决策树

停止条件：结点中的样本个数小于预定阈值或样本的基尼指数小于预定阈值或者没有更多特征

## 2. CART剪枝

CART剪枝算法由两步组成：

- 从生成算法产生的决策树$T_0$底端开始不断剪枝，直到根结点，形成一个子树序列$\{T_0,T_1,T_2,...,T_n\}$
- 通过交叉验证法在独立的验证集上对子树序列进行测试，从中选择最优子树。

具体而言，CART的剪枝算法如下：

- 设$k=0, \quad T=T_0$

- 设损失函数的参数$\alpha=+\infty$

- 自下而上对内部结点$t$计算$C(T_t),|T_t|$以及
  $$
  g(t)=\frac{C(t)-C(T_t)}{|T_t|-1}\\
  \alpha=min(\alpha,g(t))
  $$
  其中，$T_t$表示以$t$为根节点的子树，$C(T_t)$是对训练数据的误差，$|T_t|$是$T_t$的叶结点个数

- 对$g(t)=\alpha$的内部结点$t$进行剪枝，并对$t$以多数表决法决定其类别，得到树$T$

- 设$k=k+1, \quad \alpha_k=\alpha, \quad T_k=T$

- 如果$T_k$不是由根节点以及两个叶结点构成的树，则返回第二步，否则令$T_k=T_n$
- 采用交叉验证法在子树序列中选择最优子树